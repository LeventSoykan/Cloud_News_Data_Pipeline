Data Pipeline project using python and scrapy to get inital data for cloud news from website

Todo: 
Get data for last month from 5 websites
https://www.ciodive.com/topic/cloud/
https://cloud-computing.tmcnet.com/
https://www.cloudcomputing-news.net/
https://www.theguardian.com/technology/cloud-computing
https://cio.economictimes.indiatimes.com/news/cloud-computing


Use only dbt docker
Empty scrapy task for only import
Create scrape with BS4


https://www.youtube.com/watch?v=uZy2Lwioi3g
Recreate airflow image with below packages
scrapy
dbt-core
dbt-postgres
copy elt dag
https://www.youtube.com/watch?v=0UepvC9X4HY


External Python Operator
https://www.youtube.com/watch?v=mWQa5mWpMZ4

